version: "3.7"

services:
  # storage service (s3-like)
  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data

  # command line for minio
  minio-mc:
    image: minio/mc:latest
    container_name: minio-mc
    depends_on:
      - minio
    entrypoint: |
      sh -c "
      sleep 20 &&
      mc alias set myminio http://minio:9000 minioadmin minioadmin123 &&
      mc mb myminio/landing &&
      mc mb myminio/bronze &&
      mc mb myminio/silver &&
      mc mb myminio/gold
      "

  # database for airflow metadata storage
  postgres-airflow:
    image: postgres:13
    container_name: postgres-airflow
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  # pipeline orchestration service
  airflow:
    build:
      context: spotify_dataflow/
      dockerfile: spotify_dataflow/configuration/airflow/airflow.Dockerfile
    container_name: airflow
    depends_on:
      - minio
      - postgres-airflow
      - trino-init
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
      AIRFLOW__CORE__PLUGINS_FOLDER: /opt/airflow/plugins
      AIRFLOW__LOGGING__LOGGING_LEVEL: INFO
      MINIO_ENDPOINT: http://minio:9000
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin123
      SPOTIFY_CLIENT_ID: ${SPOTIFY_CLIENT_ID}
      SPOTIFY_SECRET: ${SPOTIFY_SECRET}
    command: ["airflow", "standalone"]
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # query engine main service
  trino-coordinator:
    container_name: trino
    image: trinodb/trino:latest
    hostname: trino-coordinator
    environment:
      - TRINO_ENVIRONMENT=production
    ports:
      - 8085:8090
    depends_on:
      - minio-mc
    volumes:
      - ./spotify_dataflow/spotify_dataflow/configuration/trino:/etc/trino
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8090/v1/info"]
      interval: 30s
      timeout: 10s
      retries: 5

  trino-worker:
    image: trinodb/trino:latest
    container_name: trino-worker
    hostname: trino-worker
    environment:
      - TRINO_ENVIRONMENT=production
      - TRINO_DISCOVERY_URI=http://trino-coordinator:8090
    depends_on:
      trino-coordinator:
        condition: service_healthy
    volumes:
      - ./spotify_dataflow/spotify_dataflow/configuration/trino:/etc/trino

  # initialize trino schemas
  trino-init:
    image: trinodb/trino:latest
    container_name: trino-initializer
    depends_on:
      trino-coordinator:
        condition: service_healthy
      hive-metastore: 
        condition: service_healthy
    entrypoint:
      [
        "/bin/sh",
        "-c",
        "sleep 30 && trino --server trino-coordinator:8090 -f /docker-entrypoint-initdb.d/create_schemas.sql",
      ]
    volumes:
      - ./spotify_dataflow/spotify_dataflow/configuration/trino/create_schemas.sql:/docker-entrypoint-initdb.d/create_schemas.sql

  # database for hive metastore
  mariadb:
    container_name: mariadb
    hostname: mariadb
    image: mariadb:10.5.8
    ports:
      - 3307:3306
    environment:
      - MYSQL_ROOT_PASSWORD=admin
      - MYSQL_USER=admin
      - MYSQL_PASSWORD=admin
      - MYSQL_DATABASE=metastore_db

  # hive metastore service used by trino
  hive-metastore:
    container_name: hive-metastore
    hostname: hive-metastore
    image: "bitsondatadev/hive-metastore:latest"
    ports:
      - 9083:9083 # Metastore Thrift
    volumes:
      - ./spotify_dataflow/spotify_dataflow/configuration/hive/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    environment:
      - METASTORE_DB_HOSTNAME=mariadb
    depends_on:
      - mariadb
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9083"]
      interval: 30s
      timeout: 10s
      retries: 5

  # make it possible to use docker inside airflow
  docker-socket-proxy:
    image: tecnativa/docker-socket-proxy:0.1.1
    environment:
      CONTAINERS: 1
      IMAGES: 1
      AUTH: 1
      POST: 1
    privileged: true
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    restart: always

  # ml experiment tracking service
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlflow
    ports:
      - "5000:5000"
    environment:
      MLFLOW_TRACKING_URI: "http://mlflow:5000"
    command: >
      mlflow server 
      --backend-store-uri 
      sqlite:///mlflow.db 
      --serve-artifacts
      --artifacts-destination /data/artifacts
      --host 0.0.0.0
      --port 5000

  # ml model serving
  spotify-model-serving:
    build: 
      context: ./spotify_song_genre_predictor/spotify_genre_serving/
      dockerfile: Dockerfile
    container_name: spotify-model-serving
    image: spotify-model-serving:latest
    ports:
      - "8000:8000"
    environment:
      MLFLOW_TRACKING_URI: "http://mlflow:5000"
    depends_on:
      - mlflow

volumes:
  postgres_data:
    name: postgres_volume
  minio-data:
